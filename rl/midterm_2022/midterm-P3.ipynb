{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Mapping, List\n",
    "from rl.distribution import Categorical\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.policy import FinitePolicy\n",
    "from itertools import product, chain, combinations\n",
    "from rl.dynamic_programming import policy_iteration_result, value_iteration_result\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DiceState:\n",
    "    handstate: Tuple[List[int]]\n",
    "    tablestate: Tuple[List[int]]\n",
    "    condition: int\n",
    "\n",
    "    def get_ones(self) -> int:\n",
    "        return list(self.handstate).count(1)\n",
    "\n",
    "    def calc_score(self) -> int:\n",
    "        if(self.get_ones() >= self.condition):\n",
    "            return sum(list(self.handstate))\n",
    "        else:\n",
    "            return 0    \n",
    "\n",
    "\n",
    "DiceActionMapping = Mapping[\n",
    "    DiceState,\n",
    "    Mapping[Tuple[List[int]], Categorical[Tuple[DiceState, float]]]\n",
    "]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiceMDP(FiniteMarkovDecisionProcess[int,int]):\n",
    "    def __init__(self, n, k, c):\n",
    "        self.num_dice = n\n",
    "        self.faces = k\n",
    "        self.condition = c\n",
    "\n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> DiceActionMapping:\n",
    "        d: Dict[DiceState, Dict[Tuple[List[int]], Categorical[Tuple[DiceState, float]]]] = {}\n",
    "\n",
    "\n",
    "        allcombos = list(product(range(1,self.faces + 1), repeat=self.num_dice))\n",
    "        for handamt in range(self.num_dice):\n",
    "            print(handamt)\n",
    "            print(len(allcombos))\n",
    "            for i in range(len(allcombos)):\n",
    "                if i > 2000:\n",
    "                    if i % 100 == 0:\n",
    "                        print(i)\n",
    "                combo = allcombos[i]\n",
    "                hand = []\n",
    "                if handamt != 0:\n",
    "                    hand = list(combo)[:handamt]\n",
    "\n",
    "                table = list(combo)[-(self.num_dice - handamt):]\n",
    "                state: DiceState = DiceState(tuple(hand), tuple(table), self.condition)\n",
    "\n",
    "                d1: Dict[Tuple[List[int]], Categorical[Tuple[DiceState, float]]] = {}\n",
    "\n",
    "                allactions = list(powerset(table))\n",
    "\n",
    "                handones = state.get_ones()\n",
    "\n",
    "                handscore = state.calc_score()\n",
    "\n",
    "                for act in allactions:\n",
    "\n",
    "                    reward = 0\n",
    "\n",
    "                    actones = list(act).count(1)\n",
    "\n",
    "                    if(handones + actones >= self.condition):\n",
    "                        reward = sum(hand) + sum(list(act)) - handscore\n",
    "                        \n",
    "                    new_hand = hand + list(act)\n",
    "                    if len(new_hand) == self.num_dice:\n",
    "                        new_tables = [()]\n",
    "\n",
    "                        sr_probs_dict: Dict[Tuple[DiceState, float], float] =\\\n",
    "                            {(DiceState(tuple(new_hand), (), self.condition), reward):\n",
    "                            1\n",
    "                        }\n",
    "                        d1[act] = Categorical(sr_probs_dict)\n",
    "                    else:\n",
    "\n",
    "                        new_tables = list(product(range(self.faces + 1), repeat = (self.num_dice - len(new_hand))))\n",
    "                        prob = (self.num_dice - len(new_hand))/self.faces\n",
    "\n",
    "                        sr_probs_dict: Dict[Tuple[DiceState, float], float] =\\\n",
    "                            {(DiceState(tuple(new_hand), new_table, self.condition), reward):\n",
    "                            prob for new_table in new_tables\n",
    "                            }\n",
    "                        d1[act] = Categorical(sr_probs_dict)\n",
    "                d[state] = d1\n",
    "        print(\"done\")\n",
    "        return d\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "1\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "2\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "3\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "5\n",
      "4096\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "done\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28420/170295341.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFiniteMarkovDecisionProcess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDiceState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     DiceMDP(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28420/3496824138.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, k, c)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action_transition_reward_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action_transition_reward_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDiceActionMapping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shaan\\onedrive\\desktop\\stanford\\senior winter\\reinforcement learning\\rl-book\\rl\\markov_decision_process.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mapping)\u001b[0m\n\u001b[0;32m    133\u001b[0m     ):\n\u001b[0;32m    134\u001b[0m         \u001b[0mnon_terminals\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         self.mapping = {NonTerminal(s): {a: Categorical(\n\u001b[0m\u001b[0;32m    136\u001b[0m             {(NonTerminal(s1) if s1 in non_terminals else Terminal(s1), r): p\n\u001b[0;32m    137\u001b[0m              for (s1, r), p in v.table().items()}\n",
      "\u001b[1;32mc:\\users\\shaan\\onedrive\\desktop\\stanford\\senior winter\\reinforcement learning\\rl-book\\rl\\markov_decision_process.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    133\u001b[0m     ):\n\u001b[0;32m    134\u001b[0m         \u001b[0mnon_terminals\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         self.mapping = {NonTerminal(s): {a: Categorical(\n\u001b[0m\u001b[0;32m    136\u001b[0m             {(NonTerminal(s1) if s1 in non_terminals else Terminal(s1), r): p\n\u001b[0;32m    137\u001b[0m              for (s1, r), p in v.table().items()}\n",
      "\u001b[1;32mc:\\users\\shaan\\onedrive\\desktop\\stanford\\senior winter\\reinforcement learning\\rl-book\\rl\\markov_decision_process.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mnon_terminals\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         self.mapping = {NonTerminal(s): {a: Categorical(\n\u001b[1;32m--> 136\u001b[1;33m             {(NonTerminal(s1) if s1 in non_terminals else Terminal(s1), r): p\n\u001b[0m\u001b[0;32m    137\u001b[0m              for (s1, r), p in v.table().items()}\n\u001b[0;32m    138\u001b[0m         ) for a, v in d.items()} for s, d in mapping.items()}\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "game: FiniteMarkovDecisionProcess[DiceState, int] =\\\n",
    "    DiceMDP(\n",
    "        n = 6,\n",
    "        k = 4,\n",
    "        c = 1\n",
    "    )\n",
    "\n",
    "gamma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = value_iteration_result(game, gamma)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "579dcdfb899fc187fdf97538744cc3a387eca9f5084bb8d1591af8d2d48fab3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

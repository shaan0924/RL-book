{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME 241 Assignment 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaan Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla_\\theta \\log\\pi(s,a;\\theta) = \\nabla_\\theta \\log(\\frac{e^{\\phi(s,a)^T\\theta}}{\\sum_{b\\in A}e^{\\phi(s,b)^T\\theta}}) $$\n",
    "\n",
    "$$ = \\nabla_\\theta (\\log e^{\\phi(s,a)^T\\theta} - \\log \\sum_{b\\in A}e^{\\phi(s,b)^T\\theta} ) $$\n",
    "\n",
    "$$ = \\nabla_\\theta (\\phi(s,a)^T\\theta - \\log \\sum_{b\\in A}e^{\\phi(s,b)^T\\theta}) $$\n",
    "\n",
    "$$ = \\phi(s,a) - \\frac{\\sum_{b\\in A} \\phi(s,b) e^{\\phi(s,b)^T\\theta}}{\\sum_{b\\in A}e^{\\phi(s,b)^T\\theta}} $$\n",
    "\n",
    "The term on the right simplifies to the expectation of the feature functions over the actions, so:\n",
    "\n",
    "$$ = \\phi(s,a) - E_b[\\phi(s,b)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the Action Function linear in its features, which lets the gradient w.r.t $w$ be equal to the score function:\n",
    "\n",
    "$$ Q(s,a;w) = \\sum_{i=1}^m \\frac{\\partial \\log \\pi(s,a;\\theta)}{\\partial \\theta_i} w_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E_\\pi[Q(s,a;w)] = \\sum_{a \\in A} \\pi(s,a;\\theta) Q(s,a;w) $$\n",
    "$$ = \\sum_{a \\in A} \\pi(s,a;\\theta) \\sum_{i=1}^m \\frac{\\partial \\log \\pi(s,a;\\theta)}{\\partial \\theta_i} w_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can move $\\pi$ inside the inner sum and note that the derivative of $\\log \\pi$ is $ \\frac{1}{\\pi} d \\pi$\n",
    "\n",
    "$$ \\sum_{a \\in A} \\sum_{i=1}^m \\frac{\\partial \\pi(s,a;\\theta)}{\\partial \\theta_i} w_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sums do not depend on each other so we can swap them.\n",
    "\n",
    "$$ \\sum_{i=1}^m \\sum_{a \\in A} \\frac{\\partial \\pi(s,a;\\theta)}{\\partial \\theta_i} $$\n",
    "\n",
    "The sum over all actions of $\\pi$ is just 1.\n",
    "\n",
    "$$ \\sum_{i=1}^m \\frac{\\partial 1}{\\partial \\theta_i} w_i = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the mean of $Q$ is 0 over any state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "579dcdfb899fc187fdf97538744cc3a387eca9f5084bb8d1591af8d2d48fab3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

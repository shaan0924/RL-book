{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME 241 Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaan Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a deterministic policy, the action $a$ is given by a fixed function $\\pi (s)$ that depends on the state. In this situation, there is no randomness in the action decision, as the state determines what action will be taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the 4 MDP Bellman Policy equations become the following:\n",
    "\n",
    "$ V^{\\pi_D}(s) = R(s, \\pi_D(s)) + \\gamma \\sum_{s' \\in N} P(s, \\pi_D(s), s') V^{\\pi_D}(s') $\n",
    "\n",
    "$ V^{\\pi_D}(s) = Q^{\\pi_D}(s, \\pi_D(s))$\n",
    "\n",
    "$Q^{\\pi_D}(s, \\pi_D(s)) = R(s, \\pi_D(s)) + \\gamma \\sum_{s' \\in N} P(s, \\pi_D(s), s') V^{\\pi_D}(s') $\n",
    "\n",
    "$Q^{\\pi_D}(s, \\pi_D(s)) = R(s, \\pi_D(s)) + \\gamma \\sum_{s' \\in N}P(s, \\pi(s), s') Q^{\\pi_D}(s', \\pi_D(s')) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, the $ \\sum_{a \\in A}$ gets removed because for each $s$ there is a fixed action that is taken based on $\\pi(s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the rewards, transition probabilities, and states do not depend on the explicit value of $s$. As a result, we can see that the explicit value of $s$ is irrelevant to the value function, thus implying that the value function is the same for all values of $s$. Thus, $V^*(s) = V^*(s + 1)$, and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V^*(s) = \\max_{a \\in A} [R(s,a) + \\gamma V^*(s) \\sum_{s' \\in N} P(s,a,s')] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum over all states of $P(s,a,s')$ is 1, so we get\n",
    "\n",
    "$$V^*(s) = \\max_{a \\in A} [R(s,a) + \\gamma V^*(s)] $$\n",
    "\n",
    "This causes $ \\gamma V^*(s)$ to not depend on $a$, so it can be removed from the max equation.\n",
    "\n",
    "$$ (1 - \\gamma)V^*(s) = \\max_{a \\in A} R(s,a) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R(s,a) = E[r_{t+1}|S_t = s, A_t = a] = (1 - a)a + (1+a)(1-a) $$\n",
    "$$ = (1-a)(2a + 1) = 1 + a - 2a^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of $a$ are either 0 or 1, thus $\\max_{a \\in A} R(s,a) = 1 $, when $a$ is 0. Thus,\n",
    "\n",
    "$$ V^*(s) = \\frac{1}{1 - \\gamma} = 2$$\n",
    "\n",
    "To have an optimal deterministic policy, we should hit the optimal value function for each state. As a result, because the value function is the same for all states, the optimal choice for $a$ remains the same across all $s$. Thus,\n",
    "\n",
    "$$ \\pi^*(s) = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state space of this frog problem is all lilypads from 0 to $n$.\n",
    "The action space is the set $A, B$\n",
    "For the transition function, we have\n",
    "\n",
    "if $s' = s - 1$, \n",
    "$$P(s,a,s') = \\frac{s + 1}{2n} $$\n",
    "\n",
    "if $s' = s + 1$,\n",
    "$$P(s,a,s') = \\frac{n-s + 1}{2n}$$\n",
    "\n",
    "all other cases,\n",
    "$$P(s,a,s') = \\frac{1}{2n} $$\n",
    "\n",
    "In this scenario, the frog has an equal chance of choosing either action, and thus there is a 1/2 chance of choosing either croak. In the case of croak A, the frog can only go one space forward or backward. Thus there is no way to go to any state aside from $i-1$ or $i+1$ given croak A. If the frog croaks B, then there is a $\\frac{1}{n}$ chance it can land one space away from its previous state as well, so these are included in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the value function show the probability of escaping. As such, the reward function should be an indicator of when the frog escapes. Thus, the reward will be 0 for all lilypads that are from 0 to $n-1$ and the $n$ lilypad wil have a reward of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Mapping\n",
    "from rl.distribution import Categorical\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.policy import FinitePolicy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(b,a,x,n):\n",
    "    if a == 0:\n",
    "        if x == b-1:\n",
    "            return b/n\n",
    "        elif x == b+1:\n",
    "            return (n-b)/n\n",
    "        else:\n",
    "            return 0\n",
    "    elif a == 1:\n",
    "        return 1/n\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calc_list(b,a,n):\n",
    "    if a == 0:\n",
    "        return [b-1, b+1]\n",
    "    elif a == 1:\n",
    "        endlist = list(range(n+1))\n",
    "        endlist.remove(b)\n",
    "        return endlist\n",
    "    else:\n",
    "        return range(0,n)\n",
    "\n",
    "class LilypadMDP(FiniteMarkovDecisionProcess[int,int]):\n",
    "    def __init__(self, n):\n",
    "        spaces = range(1,n)\n",
    "        self.non_terminal_states = spaces\n",
    "        actions = [0,1]\n",
    "        self.mapping = {\n",
    "            b: {\n",
    "                a: Categorical(\n",
    "                    {(x, 1 if x is n else 0): (calc_prob(b,a,x,n))\n",
    "                    for x in calc_list(b,a,n)}\n",
    "                ) for a in actions\n",
    "            } for b in spaces\n",
    "        }\n",
    "        super().__init__(self.mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57142857 0.71428571]\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "def findoptimals(n):\n",
    "    optimalpol = [0]*(n-1)\n",
    "    lily = LilypadMDP(n)\n",
    "\n",
    "    mapping = {\n",
    "        b: Categorical({optimalpol[b-1]: 1}) for b in range(1,n)\n",
    "    }\n",
    "    newpol = FinitePolicy(mapping)\n",
    "    MRP = lily.apply_finite_policy(newpol)\n",
    "    lilyvalue = MRP.get_value_function_vec(1)\n",
    "    \n",
    "    power = pow(2,(n-1))\n",
    "    for i in range(1,power):\n",
    "        lilylist = [int(i) for i in list(np.binary_repr(i, width=(n-1)))]\n",
    "        mapping = {\n",
    "            b: Categorical({lilylist[b-1]:1}) for b in range(1,n)\n",
    "        }\n",
    "        newpol = FinitePolicy(mapping)\n",
    "        MRP = lily.apply_finite_policy(newpol)\n",
    "        newval = MRP.get_value_function_vec(1)\n",
    "        if np.all(np.greater(newval,lilyvalue)):\n",
    "            lilyvalue = newval\n",
    "            optimalpol = lilylist\n",
    "    \n",
    "    return lilyvalue, optimalpol\n",
    "\n",
    "x,y = findoptimals(3)\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65957447 0.70212766 0.72340426 0.74468085 0.78723404]\n",
      "[1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "x,y = findoptimals(6)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67567568 0.70523649 0.71368243 0.71790541 0.72128378 0.72550676\n",
      " 0.7339527  0.76351351]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "x,y = findoptimals(9)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dacf38ef70>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlc0lEQVR4nO3deXyU9b3+/9c7C1kI2SBAZE9kC1QBp4pK1aqguIDWpeLSzZbW6qnLaXu0tqf92ZbaX21LT4+1daunbqjUBRUFq9aF1iWsssuiLAIJhEVMAlk+3z/uIWSZJJMw4Z7lej4e82BmPvfMfYlwcedzb+acQ0REYl+S3wFERCQyVOgiInFChS4iEidU6CIicUKFLiISJ1L8WnGvXr3c4MGD/Vq9iEhMWrhw4U7nXEGoMd8KffDgwZSWlvq1ehGRmGRmH7c2pikXEZE4oUIXEYkTKnQRkTihQhcRiRMqdBGRONFuoZvZg2ZWZmbLWxk3M/sfM1tnZsvMbFzkY4qISHvC2UJ/CDi3jfHJwNDgYzpwz5HHEhGRjmq30J1zbwIVbSwyFfib87wD5JpZYaQCiohIeCIxh94P2Nzo9Zbgey2Y2XQzKzWz0vLy8k6t7P7f/oGS6zJ577V/d+rzIiLx6qjuFHXO3eucCzjnAgUFIc9cbVdubk9W9a1i3stPRjidiEhsi0ShbwUGNHrdP/helzjv8i+RUQPLtr/RVasQEYlJkSj0OcBXgke7jAf2Oue2ReB7Q8rskcnIHdmszfiwq1YhIhKT2r04l5k9DpwB9DKzLcBPgVQA59yfgbnAecA6oBL4eleFPWTogeE8M+h99lXsIzs/u6tXJyISE9otdOfctHbGHXB9xBKF4QvDL6Z87XY2b9jEqPzRR3PVIiJRy7w+PvoCgYDT5XNFRDrGzBY65wKhxmL61P9N6zb5HUFEJGrEbKFPvaaEU+8u8juGiEjUiNlC758+jC25dSx7Z4nfUUREokLMFvopYy8AYO6cx31OIiISHWK20C+84nK61cLSLf/0O4qISFSI2ULPzs9mRFl31qat9juKiEhUaPc49Gh2ee63qXf1fscQEYkKMV3ot//6t35HEBGJGjE75QJQX1fPc397kpdmPed3FBER38V0oQNMXzaNmXNv9juGiIjvYrrQk5KTGLGzD2vztvgdRUTEdzFd6AAjksfwUX4Na5et8TuKiIivYr7QTxo1GYAXn9YJRiKS2GK+0C/48pdJrodFG//hdxQREV/F9GGLAL379eb+/Ls5Y9pkv6OIiPgq5gsd4Gs3ftfvCCIivov5KReAZe8s4dqvn82bL77mdxQREd/ERaHvKivnwcGv8vzch/yOIiLim7go9NPPP4v8SmPlvnf8jiIi4pu4KPSk5CRGlhWwNke3pBORxBUXhQ4wnM+xruAAH6/92O8oIiK+iJtC//zwc0ivgQX/0PHoIpKYzDnny4oDgYArLS2N2PdVV1ZTX1dPZo/MiH2niEi0MbOFzrlAqLG4OA4dID0z3e8IIiK+ipspF4A7fnAjJ12bT21Nrd9RRESOurgq9Mrqfbw3cDevz5nvdxQRkaMurgr99AkXA/D6G0/7nERE5OiLq0Kf+KXzyK6GFbv/5XcUEZGjLq4KPSU1hZIdPVmTvdHvKCIiR11cFTpAIOU0jtnfUztGRSThhHXYopmdC/wBSAbud87d2Wx8IPB/QG5wmVudc3MjGzU8f7xX8+cikpja3UI3s2TgbmAyUAJMM7OSZov9GHjSOTcWuAL4U6SDdtT+vfv9jiAiclSFM+VyIrDOObfBOXcQmAVMbbaMA7KDz3OATyIXseNO/kYvJt90rJ8RRESOunAKvR+wudHrLcH3GvsZcLWZbQHmAv8R6ovMbLqZlZpZaXl5eSfihievNo/VBWXU19V32TpERKJNpHaKTgMecs71B84DHjazFt/tnLvXORdwzgUKCgoitOqWSrJOZGd3x9sv/7PL1iESFudg/XqYPRtmzvQ7jcS5cAp9KzCg0ev+wfcauxZ4EsA5928gHegViYCdcdop3glGr746268Ikohqa2HFCnjkEbjlFjjjDMjLg2OPhcsug9tug4MH/U4pcSyco1zeB4aa2RC8Ir8CuLLZMpuAs4CHzGwkXqF33ZxKO869dArdfw4flL/tVwSJdwcOwPLlsGgRLF7s/bpsGVRVeePp6XD88TBtGowbB2PHwujR0K2bv7klrrVb6M65WjO7AZiHd0jig865FWZ2B1DqnJsD/Cdwn5ndjLeD9GvOr+vyAt3Su/GVHRdw7JCxfkWQePLpp7B06eHiXrzY2xKvDZ7rkJ3tFfZ3vuP9Om4cDB8OKXFzMVOJEXFzPXSRiNi1q2lxL1oEH37ozYUDFBR4hX3oMXYsDBkCSXF3jp5EqYS4HnpztTW1vPL0XPoNGshx48f4HUeijXPwyScty3tTo/vSDhzolfZVVx0u72OOATP/ckvMcM5RUVXB+t3r2bB7Axt2b2B9xXo27NnALeNv4cLhF0Z8nXFb6GuXreG81VP5zivnc8/4F/yOI35yDjZsaFrcixdDWZk3bgbDhsEpp8ANN3jFPXYs9Ozpb26JejV1NWzet9kr6t0bmpb37vXsO7CvyfKFWYUU5RVR77rmkOq4LfSSE0Yx8OEUVtcu9juKHE21tbB6ddPiXrwY9gX/YqWkwKhRcP75h+e7jz8esrL8zS1Ra2/13pBb2esr1rNp7ybqXF3DsmnJaQzJG0JRXhGnDjiV4vxiivKKKM4rZkjeEDJTu/YWmXFb6AAjKvqztPcm6uvqSUrWHGfcqa72jjQ5VN6HjjSprvbGMzLguOO8KZND5T16NKSl+ZtbokpdfR1bP93a6lZ2RVVFk+V7ZfaiOK+Y8f3Hc9XnrqIor8gr7fxijulxDEktT8E5auK70DMCzO/xEQvfep/Pn3GS33EkHM55R5Vs2+Y9tm8//Lz564pGf9FycrzSvu66w/PdOtJEgvYf3N9Q0s23sj/a8xE19TUNy6YkpTAoZxDF+cVcXnh5w1b2oUd2WnYba/JXXP9pPzVwIf/zyWzmz31Che63+nrYubP1cm78XmVly8936waFhdC3LwwdCqed5j0vKfEKfMgQ7axMYPWunm2fbmuyZd3417LPyposn5OWQ3F+MWP6juFLI79Ecd7h0h6QM4CUpNisxthMHaYLrriUu37zIZd84xt+R4lfBw4cLua2tqZ37IC6upafz872irqwEE46ySvpQ68PFXhhoXfGpQo7ZtXV11FVW0VlTWWTR1VNy/cqaypDLtvW+xVVFVTXVjesL8mSGJA9gOL8YqYMm9IwJXJoPjsvI8/H342uo+PQpaXm0x5tlXVFRcvPm0Hv3k0LuXlBH3qe2bU7icQ7fK7O1VFTV0NNfU2LX2vra0OOHSrPjpRua4V7sK7jlzwwjMzUzIZHRmpGk9cNj5RMctJzGsq6KK+IQbmD6JYcn2flJuRx6Ie88cKrPPbMXfzmN0+QnR+9c19HRX09lJe3vSXd1rRHWtrhQh42DE4/PXRh9+4dM3PXh8qutr62U4+6+o59NlShtlm0HVi+pq71z0RS86JtXLbZadn0zerbULStlXBGSivl3Oi70pLTMP1U1iGx8bfuCCx4+2XuHfgyp896iiu/e+1RX395OfTo4V3ao8u0Ne3R+L3Wpj1ycppOezQqaNenD3V9e1PTpxc1PbpT28aWXk1dDTV1H1Gz5cOwyijcwmpruYZi7WQpd9XxwOFKsiRSk1JJTU5t8WtKUkrIsbSUNLKSslq839rybf3a1meal66KNvrFfaGfN2Uat79yF/9e8iJXcvQK3TmYNQu+9z341rdgxoxOfEHzaY9t26jfvo3q7VuoLNtK5a7tVFWUUVm5l8pUmjyqUqEyvweVeVlUju1O5ek9qexeSFVmKpXpyVR2MypTHJVJdVTWVQd/tF5HVe0HXmEerKFmQw016yK7ddcWwzpcOilJKaSlpJGSlNL6w1q+l5yU3PZn2ngkW+c+m5yU3CK/n4e4SfyJ+0Ifc8o4jpmdzOoDC4/aOrdsge9c53jxtV2MmrCRIWfv4bnVwfnEg/up2lNOZUUZlXt3UrlvF5Wf7aaych9V1fupPPgZlbVVVNYfoDK5/nA5Hyrq7kBx8NGuT4MPSE9JbzLnmJmcSUZyBpmp3emZWtAwlp6S3qmtuRZbip3YOkxOSu66/ykiCSDuCx1gxK5C1uRH/q54NXU1fLz344ZDpdZVrOe1RRtYtnkdfG49BD5jBTD9rda/I6MGMmsgo87ITEolM6MbmSndyUwtoFdaFhkZ2WR2zyWzRz6Z2T3JzMojs1v3VucgQ81Zpqeka0tQJAEkRKEP7zaOt7PmsGHleopKwtq0bbCnek/DGWTNj2/dtHdTkznY1Nok+u9O5Zw9Byne6CjaDUXVGfTM70dmXm8yexaSUVBIZu9+ZBYOJP2YgSQd08/bkZiREen/bBFJMAlx2OL2zdtJz0gnt1dui7G6+jq27NvS4nTfQ2eT7a7e3WT5gpQciuqyKd5jFG3eT9G6Cop3Q9FuSPm0gJpRJ9D/wnHYuLE64UVEIi6hD1sE6N67Oxv3bOT1Va+3uFZDqNN+B+cOpjijH5/PGk9RdS3FG/ZQtHQTRat20OPgXmAvDBrE3mNP5/Hysfx66zh6TxrLLx4oZEB/lbeI+CMuCr3xab/NT/ldX7Ge8sqmd8PLS8+jKK+IsYVjuWTElyiuy6ZoWzVFH5bTf+E6UhYvhfJ13sJm3jVBxp4JV3vXCDlQMpYZf85nxgzvBMb/fcK7ZaQ2xEXETzFX6B/s+IDXNr7WpLQ37tnY4rTfgTkDKc4r5qIRF1GUV8Szj/6FJT0/YuPkVylcv6XRpVVf8g4PBO9kmNGj4YILDl/gqdmlVd95B649G1auhKuv9m7krstmi0g0iLlCn79+Pt9/5ftkdcuiOK+YkQUjOX/o+U2uiDYoZxCpNXXwwQdeab+4iD4fVPKNSbDtsrMo3Ia3E/L44+Gaaw5fWnXUqFYvrfrZZ/CTn3gF3q8fvPginHfeUf1PFxFpU8wV+rXjruWrY75Kz4yeh89W27fPu4nvgkWw+DFv63vlysNnRebkcMqoIUAZz044iXE/e9CbRkkO77jnV1/1Tg7auNG7Ouudd3rXlBIRiSYxV+i5lfVQ2uxWYh9+eHiBPn28re0pUw5veQ8ezNB6R8GtqbybXuZdcjUMe/bAD34A99/vXbH1jTe8q7aKiESjmCt07rkHfvxj7/ngwV5hf+Urh+e8CwtDfiwp2fj89mJSSA1rNc89522Nl5XBf/0X/PSnOlRcRKJb7BX6tGlw8skwZgzk53fooy8+vLbdZXbs8K6/8uST3hT788/DCSd0MquIyFEUe4VeVOQ9jkCoe4w6B48+CjfeCPv3wy9+AT/8IaSGt0EvIuK7hLrAR3VlNcNuSOdr3zi9yfubNnk3gb/mGm9f6ZIlcPvtKnMRiS0JVejpmemk1CWxJmUF4N3v4U9/8o5WfOMN+MMf4K23YORIn4OKiHRCQhU6wLD9Razqs5vlHxzkjDPg+uu9Kfnly7258zCPZBQRiToJV+ij8ifwaRpcds7zfPAB/PWvMG+edw0tEZFYllCFvnQpvPXmJQAMHfUcK1fC176ma7CISHxIiEKvrvYOXQ8EYPXWs5i8ahRTzhnX2iHrIiIxKazDFs3sXOAPQDJwv3PuzhDLXA78DHDAUufclRHM2Wn/+hdcey2sXg1f/Sr87ndJ5Ocv9zuWiEjEtbuFbmbJwN3AZKAEmGZmJc2WGQrcBpzqnBsF3BT5qB2zf7+3k3PCBKishJdfhoce8s5Fqq+r5/U5r7Bz206/Y4qIREw4Uy4nAuuccxuccweBWcDUZst8C7jbObcbwDlXFtmYHTN/vncV3P/9X+8oluXL4ZxzDo/fd9fvOXPxJJ548D7/QoqIRFg4hd4P2Nzo9Zbge40NA4aZ2QIzeyc4RdOCmU03s1IzKy0vLw+1yBGpqICvf90r7/R0ePNN+OMfoUePpsudf9mXMQel616JeAYREb9EaqdoCjAUOAOYBtxnZrnNF3LO3eucCzjnAgUFBRFatefvf/cuovjww3Dbbd7ZnhMmhF62f1F/hpanscY+iGgGERE/hVPoW4EBjV73D77X2BZgjnOuxjm3EViLV/Bdbvt2uPRS71FYCO+/DzNmeFvobRn26RBW9d5FbU3t0YgpItLlwin094GhZjbEzLoBVwBzmi3zLN7WOWbWC28KZkPkYrbknLeTs6QEXnjBK/H33vOuoBuOUTnj2ZPh+OfzmnYRkfjQ7mGLzrlaM7sBmId32OKDzrkVZnYHUOqcmxMcm2RmK4E64AfOuV1dFfqjj+Db3/Z2fp56qncDihEjOvYdV0z7D3KfL6Bk3PFdklFE5Ggz55wvKw4EAq60tLTDn3v0Ua/MzbxbwV13HSQlxOlRIiJgZgudc4FQYzFXhYWF8IUveIciXn/9kZX5S7Oe4/YbvxW5cCIiPoq5Qj/zTHjpJRg06Mi/a9bLv+PO3PvZvnn7kX+ZiIjPYq7QI2nckLOoT4I5jz/mdxQRkSOW0IV+4WVXAfD+6nk+JxEROXIJXehFJcUU7erGmvplfkcRETliCV3oAMP2DODDnmXU19X7HUVE5IiEdfncePabG56m74BjSEpO+H/bRCTGJXyhjz7xOL8jiIhEhDZLgW9+fSI3fedyv2OIiByRhN9CB1iaXEoVB/2OISJyRLSFDgyrGcma3pVUlFX4HUVEpNNU6MCYAV+kNhmef/wJv6OIiHSaCh0476JpALz7wVyfk4iIdJ4KHRgVGE3J9gwO1FX5HUVEpNO0UzRoxT2VfkcQETki2kIXEYkTKvSg9177N8OvT2fGrT/wO4qISKeo0INKTvgcm/IOsOST1/2OIiLSKSr0oKycLEaU9WBt+hq/o4iIdIoKvZHh1cNZ3Wc/+yr2+R1FRKTDVOiNHHfMGRxIgRdmPeV3FBGRDlOhN3LBRVcxaf1gMrtn+R1FRKTDdBx6I8eNH8O88Rv9jiEi0inaQm+mvq6e9//5rt8xREQ6TIXezC3XX8GJb4xn2TtL/I4iItIhKvRmAqPPBuDl53XlRRGJLSr0Zi644nJS62DJZp1gJCKxRYXeTG6vXEbs6M6atNV+RxER6RAVegjDqoayqs9eqiur/Y4iIhI2HbYYwrTTv89xq9+jtqbW7ygiImEz55wvKw4EAq60tNSXdYuIxCozW+icC4QaC2vKxczONbM1ZrbOzG5tY7lLzMyZWciVxZI5j8zm7hl3+h1DRCRs7Ra6mSUDdwOTgRJgmpmVhFiuB3AjEBdn5fz2H9/jru3/7XcMEZGwhbOFfiKwzjm3wTl3EJgFTA2x3M+BXwNxsSdxRPLxfNSzhnXLP/Q7iohIWMIp9H7A5kavtwTfa2Bm44ABzrkX2/oiM5tuZqVmVlpeXt7hsEfT50vOBeD52Y/6nEREJDxHfNiimSUBvwP+s71lnXP3OucCzrlAQUHBka66S025YhrJ9bB446t+RxERCUs4hb4VGNDodf/ge4f0AEYD/zSzj4DxwJxY3zHau19vhpVlsCZlpd9RRETCEs5x6O8DQ81sCF6RXwFceWjQObcX6HXotZn9E/i+cy7mj0n84znPMPy4UX7HEBEJS7uF7pyrNbMbgHlAMvCgc26Fmd0BlDrn5nR1SL+cddE5fkcQEQlbWGeKOufmAnObvRfymD7n3BlHHis67Nm5hxu/P5UTiifyvZ/82O84IiJt0rVc2pCdl83zfd5i/tqH/Y4iItIuFXobkpKTKCnrxZqcj/2OIiLSLhV6O4ZzHOsKDvDxWpW6iEQ3FXo7AsMmAfDC7Md9TiIi0jYVejvOv+wKsqvhkx3r/Y4iItImXQ+9HQOPHciuO2pISdVvlYhEN22hh0FlLiKxQIUehof/+BdGXZfJq8/O8zuKiEirVOhh6FXQl5V9q3jt9dl+RxERaZUKPQwTLzmf7GpYXvEvv6OIiLRKhR6GlNQURpbl82GPjX5HERFplQo9TMPqRrGmoIrtm7f7HUVEJCQVephO+9wlnPHRAD75eIvfUUREQjLnnC8rDgQCrrQ05i+ZLiJyVJnZQudcyBsIaQu9g3RNFxGJVir0Drj0K2MJ3DeE+rp6v6OIiLSgQu+AQd1HsjPL8e9/vO13FBGRFlToHfCF8VMBmD/vCZ+TiIi0pELvgHMvm0r3g7C8XFvoIhJ9VOgdkJ6Zzsgduazpvs7vKCIiLegygh10ed/rqKz61O8YIiItqNA76Ae/mOF3BBGRkDTl0glzHpnNc3970u8YIiJNqNA74YbSacx89Ra/Y4iINKFC74QRFf1Y02ub3zFERJpQoXfCyIwA27LrWfjm+35HERFpoELvhFNOuBCAl1943OckIiKHqdA74fwvX0J6DSzd/qbfUUREGuiwxU7Iysnivr5/4ZQrz/I7iohIAxV6J119w3S/I4iINBHWlIuZnWtma8xsnZndGmL8FjNbaWbLzOxVMxsU+ajRZeXCFXzz6xN55e9z/Y4iIgKEUehmlgzcDUwGSoBpZlbSbLHFQMA5dxwwG/j/Ix002lRXVfHA4H/w/LwH/I4iIgKEt4V+IrDOObfBOXcQmAVMbbyAc+5151xl8OU7QP/Ixow+4yYEKNybzKrqhX5HEREBwiv0fsDmRq+3BN9rzbXAS6EGzGy6mZWaWWl5eXn4KaPUiF19WdNzq98xRESACB+2aGZXAwHgN6HGnXP3OucCzrlAQUFBJFftixHdTmBzbi3L31vmdxQRkbAKfSswoNHr/sH3mjCzs4HbgSnOuQORiRfdTj7uPNJr4L233/A7iogI5pxrewGzFGAtcBZekb8PXOmcW9FombF4O0PPdc59GM6KA4GAKy0t7WzuqHCw+iC1NbVk9sj0O4qIJAgzW+icC4Qaa/c4dOdcrZndAMwDkoEHnXMrzOwOoNQ5NwdviiULeMrMADY556ZE7L8gSnVL70a39G5+xxARAcI8scg5NxeY2+y9/270/OwI54oZd972Q57aeS8L/rCd9Mx0v+OISALTtVyO0IGDVSzqv5e5TzzjdxQRSXAq9CN09qTLAHj7vTk+JxGRRKdCP0Innz2Bgv1JrPrsPb+jiEiCU6EfoaTkJEaW92ZN7ub2FxYR6UIq9AgIZHyRgft6UflpZfsLi4h0EV0+NwJ+e89jfkcQEdEWeiTtq9jndwQRSWDaQo+QL3y9LweTanj3gV1+RxGRBKUt9AjJr+3Jqj4VHKw+6HcUEUlQKvQI+Vz+qXyaBq8886LfUUQkQanQI+SLX7wEgDcXPOtvEBFJWCr0CPnihRPJrTJW7H3H7ygikqC0UzRCkpKTuKbiYvoPHOZ3FBFJUCr0CPqfe//udwQRSWCacomg2ppa5j31Aoveju0bd4hIbFKhR9AnH3/C5BUX8scHfuh3FBFJQCr0CBp47ECO3ZnGWlvudxQRSUAq9AgbtncQK3vvpL6u3u8oIpJgVOgRNirnZPZkOF57bp7fUUQkwajQI+yMCRcD8PobT/ucREQSjQo9wiZecj531f2Ya799q99RRCTB6Dj0CEtJTeE/7/i53zFEJAFpC70LLJj3Jt++9jy2b97udxQRSSAq9C5Q+s4/uXfgS7zwxCy/o4hIAlGhd4HzL5kGwHsrX/Y5iYgkEhV6Fzh29FCG7EplTf1Sv6OISAJRoXeR4XsGsLJgh04wEpGjRoXeRUq6n8TeDMeyd5f4HUVEEoQ553xZcSAQcKWl8XtVwrKtZXRL60Zur1y/o4hIHDGzhc65QKgxHYfeRXr36+13BBFJMJpy6ULf/+7VXPiVkX7HEJEEEVahm9m5ZrbGzNaZWYtz2s0szcyeCI6/a2aDI540Bm37bD0vD15NRVmF31FEJAG0W+hmlgzcDUwGSoBpZlbSbLFrgd3OuWOB3wO/jnTQWDRmwBepTYYXZj3ldxQRSQDt7hQ1s5OBnznnzgm+vg3AOferRsvMCy7zbzNLAbYDBa6NL4/3naIAK0qXM/rFz1G4P4nLU45j5q8WA3DKTT3Ym1TTZNmp3ccx4+f/AmDMzRnUWNPfuivzvsDtP3mFmupKxvwov8W6vtn7XG6+9Vn27PiYU389vMX4jQMvZfpNj7B1bSmT/jyhxfiPhn2Dq77zJ9aWzuPix6a2GP/l8Tdz0Vd/xZI3nuCq577aYvz343/KpMtvY8GL9zD91ZtbjP/lzN8x4YLvMv/JX3HzO/9fi/FHpvyVsWdM49n/u43bl/6+xfgzVz7HsMA5PPrn7zJj7YMtxud/5236DQtw38yvMHPTky3GF/zXGnL7DGLmry/mvh0vtRhf/MuddMvI4pc/n8hju99qMpbijKW/rwLgRz85hec+W9RkPKc+lX/N/BSAm24byysHVjUZP6a+O6/M3AXA9Oens2DzgibjQ/OH8uwVzwJw1dNXsWT7kibjx/c5nscueQyAi2ZdxIcVHzYZP6X/Kdw35T4AJj48kU8+/aTJ+MSiicw8d6a37AOnsPfA3ibjU4dPZcZZMwAY8+cx1NQ3/bN55egruf2026mpq2HMX8bQ3DfHfpObT76ZPdV7OPXBU1uM33jSjUw/YTpb921l0iOTWoz/aMKPuOq4q1i7ay0XP3Fxi/FfnvlLLhpxEUu2L+Gqp69qMf77c37PpOJJLNi0gOkvTG8x/pcL/sKEgROYv34+N89r+WfzkYsfYWzhWJ5d/Sy3v3Z7i/FnvvwMw3oO49FljzLj7RktxudfPZ9+2f24b+F9zHx3ZovxBd9YQG56LjPfmcl9i+5j8rGTuWvSXS2WC9eR7hTtB2xu9HoLcFJryzjnas1sL9AT2NksyHRgOsDAgQPDCh/LRgVG85PnT2NV3Xr65/dreH94Sl/211c1WbZfTv+G5yOTelPr6pqM9805/PkSerVYV+/cYwBITkkNOd4rxxtP7ZYRcjw/py8AaRlZIcdzsgsAyMjMDjmeHRzP6tEz5HhWj54Ny4Uaz+ye27CeUONpGVkNOUONp3bLAKBXbiElm1qOJ6ekAtA75xhKdrQcN/N+WO2b04+S3U3HU5KSG573y+lPyWebmv63pWQ0PO+f3Y+S8vIm4wVpuQ3PB+YMZHf17ibjA7MP/10YnDOYg3UHm4wPyR3S8Lw4r5jU5NSmn885/Pmh+UPJTc9tMt4/+/CfreG9hrP/4P4m4/16HP6zNbJgJLX1tU3G+2b1bXheUtD8h3Po3d07ACDZkkOO98r0fj9Tk1NDjudneBsoaclpIcdz0nIAyEjJCDmenZYNQFa3rJDjWd2yGpYLNZ6ZmtmwnlDjaclpDTlDjR/6/9Ers1fI8WTz/vz07t6bkoKSJr/fkRbOFvqlwLnOuW8GX18DnOScu6HRMsuDy2wJvl4fXGZnqO+ExNhCFxGJtLa20MPZKboVGNDodf/geyGXCU655AC7Oh5VREQ6K5xCfx8YamZDzKwbcAUwp9kyc4BDE6uXAq+1NX8uIiKR1+4cenBO/AZgHpAMPOicW2FmdwClzrk5wAPAw2a2DqjAK30RETmKwjpT1Dk3F5jb7L3/bvS8GrgsstFERKQjdKaoiEicUKGLiMQJFbqISJxQoYuIxAnfroduZuXAx538eC+anYUa5WIpbyxlhdjKG0tZIbbyxlJWOLK8g5xzBaEGfCv0I2Fmpa2dKRWNYilvLGWF2MobS1khtvLGUlbouryachERiRMqdBGROBGrhX6v3wE6KJbyxlJWiK28sZQVYitvLGWFLsobk3PoIiLSUqxuoYuISDMqdBGROBFThW5mD5pZWfCGGlHNzAaY2etmttLMVpjZjX5naouZpZvZe2a2NJi35X3iooyZJZvZYjN7we8s7TGzj8zsAzNbYmZRfWcXM8s1s9lmttrMVgVvQxmVzGx48Pf00GOfmd3kd67WmNnNwb9fy83scTNLj+j3x9IcupmdBuwH/uacG+13nraYWSFQ6JxbZGY9gIXARc65lT5HC8nMDOjunNtvZqnA28CNzrl3fI7WKjO7BQgA2c65C/zO0xYz+wgItHUXr2hhZv8HvOWcuz94D4RM59wen2O1K3hD+614d0vr7EmLXcbM+uH9vSpxzlWZ2ZPAXOfcQ5FaR0xtoTvn3sS73nrUc85tc84tCj7/FFiFd+/VqOQ8h242mRp8RO2/9mbWHzgfuN/vLPHEzHKA0/DucYBz7mAslHnQWcD6aCzzRlKAjOCd3TKBT9pZvkNiqtBjlZkNBsYC7/ocpU3BKYwlQBnwinMumvPOBH4I1PucI1wOmG9mC4M3S49WQ4By4K/B6az7zay736HCdAXwuN8hWuOc2wrcBWwCtgF7nXPzI7kOFXoXM7Ms4O/ATc65fX7naYtzrs45NwbvvrEnmllUTmuZ2QVAmXNuod9ZOmCCc24cMBm4Pjh9GI1SgHHAPc65scBnwK3+RmpfcGpoCvCU31laY2Z5wFS8fzSPAbqb2dWRXIcKvQsF56L/DjzqnHva7zzhCv6I/Tpwrs9RWnMqMCU4Lz0LONPMHvE3UtuCW2c458qAZ4AT/U3Uqi3AlkY/nc3GK/hoNxlY5Jzb4XeQNpwNbHTOlTvnaoCngVMiuQIVehcJ7mR8AFjlnPud33naY2YFZpYbfJ4BTARW+xqqFc6525xz/Z1zg/F+zH7NORfRLZ1IMrPuwR3jBKcvJgFReaSWc247sNnMhgffOguIyh35zUwjiqdbgjYB480sM9gPZ+HtW4uYmCp0M3sc+Dcw3My2mNm1fmdqw6nANXhbj4cOqTrP71BtKAReN7NlwPt4c+hRfzhgjOgDvG1mS4H3gBedcy/7nKkt/wE8GvyzMAaY4W+ctgX/kZyIt8UbtYI/9cwGFgEf4PVvRC8BEFOHLYqISOtiagtdRERap0IXEYkTKnQRkTihQhcRiRMqdBGROKFCFxGJEyp0EZE48f8A+DOrIejoKQsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob3, croak3 = findoptimals(3)\n",
    "prob6, croak6 = findoptimals(6)\n",
    "prob9, croak9 = findoptimals(9)\n",
    "\n",
    "xaxis3 = [1,2]\n",
    "xaxis6 = [1,2,3,4,5]\n",
    "xaxis9 = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "plt.plot(xaxis3,prob3, c = 'blue')\n",
    "plt.plot(xaxis3,croak3, c = 'blue', linestyle = 'dashed')\n",
    "plt.plot(xaxis6,prob6, c = 'red')\n",
    "plt.plot(xaxis6,croak6, c = 'red', linestyle = 'dashed')\n",
    "plt.plot(xaxis9,prob9, c = 'green')\n",
    "plt.plot(xaxis9,croak9, c = 'green', linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows the Optimal Croaks and Optimal Probabilities for each lilypad given a specific $n$ (blue is 3 pads, red is 6, and green is 9). As we can see, the Optimal Croak strategy remains the same across all $n$; use croak B on the first pad and then use croak A for all other pads. This is due to the fact that using croak A on pad 1 will lead to a significantly higher chance of getting eaten than using croak B. For all other situations, using croak A is better as the chance of getting eaten is 0, and there is no time constraint on getting to the other side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Expected Discounted Sum of Costs can be modeled through the MDP Bellman Policy Equation\n",
    "\n",
    "$$V^\\pi(s) = \\sum_{a \\in A} \\pi(s,a) [R(s,a) + \\gamma \\sum_{s' \\in N} P(s,a,s') V^\\pi(s')] $$\n",
    "\n",
    "In the myopic case, $\\gamma$ is 0, so the equation simplifies to \n",
    "\n",
    "$$V^\\pi(s) = \\sum_{a \\in A} \\pi(s,a) R(s,a) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in the continuous case, so the sum is replaced with an integral, giving us\n",
    "\n",
    "$$V^\\pi(s) = \\int_{A} \\pi(s,a) R(s,a) da$$\n",
    "\n",
    "The reward function $R$ is the expected return in the next period given current state $s$ and action $a$. Thus, because $s'$ follows a $N(s,\\sigma)$ distribution, we can see that\n",
    "\n",
    "$$ R(s,a) = E[e^{as'}] = \\int_{\\infty}^{\\infty} e^{ax} \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{\\frac{-1}{2}(\\frac{x - s}{\\sigma})^2} dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exponents, we have $2\\sigma^2 ax - x^2 + 2xs - s^2 $ so we can complete the square to get $$(-x^2 + 2x(s + \\sigma^2 a) - (s + \\sigma^2 a)^2) + 2\\sigma^2 as +  \\sigma^4 a^2 $$ or $$-(x - s - \\sigma^2 a)^2 + 2\\sigma^2 as + \\sigma^4 a^2  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the latter two terms have no x, we can take them out of the integral\n",
    "\n",
    "$$ e^{\\frac{\\sigma^2 a (2s + \\sigma^2 a)}{2\\sigma^2}} \\int_\\infty^\\infty \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{\\frac{-1}{2} (\\frac{x - s - \\sigma^2 a}{\\sigma})^2} dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral thus simplifies to the pdf of a $N(s + \\sigma^2 a, \\sigma)$ distribution, so integrating it over all real values equates it to 1. So,\n",
    "\n",
    "$$R(s,a) = e^{\\frac{a (2s + \\sigma^2 a)}{2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the value function we see that\n",
    "\n",
    "$$V^\\pi(s) = \\int_A \\pi(s,a) e^{\\frac{a (2s + \\sigma^2 a)}{2}} da$$\n",
    "\n",
    "For any s, the minimum value of this function (provided that $\\pi(s,a)$ is 1 at this minimum value and 0 everywhere else) is when $a(2s + \\sigma^2 a)$ is at its minimum. Therefore, the minimum is reached when $2s + 2\\sigma^2 a= 0$, or\n",
    "\n",
    "$$ a = \\frac{-s}{\\sigma^2} $$\n",
    "\n",
    "This provides a cost of $e^{\\frac{-ss'}{\\sigma^2}}$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "579dcdfb899fc187fdf97538744cc3a387eca9f5084bb8d1591af8d2d48fab3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
